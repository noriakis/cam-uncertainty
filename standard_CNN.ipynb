{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cfa0c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current layer: 1 rescaling_3\n",
      "current layer: 2 normalization_3\n",
      "current layer: 3 stem_conv_pad\n",
      "current layer: 4 stem_conv\n",
      "current layer: 5 stem_bn\n",
      "current layer: 6 stem_activation\n",
      "current layer: 7 block1a_dwconv\n",
      "current layer: 8 block1a_bn\n",
      "current layer: 9 block1a_activation\n",
      "current layer: 10 block1a_se_squeeze\n",
      "current layer: 11 block1a_se_reshape\n",
      "current layer: 12 block1a_se_reduce\n",
      "current layer: 13 block1a_se_expand\n",
      "current layer: 14 block1a_se_excite\n",
      "current layer: 15 block1a_project_conv\n",
      "current layer: 16 block1a_project_bn\n",
      "current layer: 17 block2a_expand_conv\n",
      "current layer: 18 block2a_expand_bn\n",
      "current layer: 19 block2a_expand_activation\n",
      "current layer: 20 block2a_dwconv_pad\n",
      "current layer: 21 block2a_dwconv\n",
      "current layer: 22 block2a_bn\n",
      "current layer: 23 block2a_activation\n",
      "current layer: 24 block2a_se_squeeze\n",
      "current layer: 25 block2a_se_reshape\n",
      "current layer: 26 block2a_se_reduce\n",
      "current layer: 27 block2a_se_expand\n",
      "current layer: 28 block2a_se_excite\n",
      "current layer: 29 block2a_project_conv\n",
      "current layer: 30 block2a_project_bn\n",
      "current layer: 31 block2b_expand_conv\n",
      "current layer: 32 block2b_expand_bn\n",
      "current layer: 33 block2b_expand_activation\n",
      "current layer: 34 block2b_dwconv\n",
      "current layer: 35 block2b_bn\n",
      "current layer: 36 block2b_activation\n",
      "current layer: 37 block2b_se_squeeze\n",
      "current layer: 38 block2b_se_reshape\n",
      "current layer: 39 block2b_se_reduce\n",
      "current layer: 40 block2b_se_expand\n",
      "current layer: 41 block2b_se_excite\n",
      "current layer: 42 block2b_project_conv\n",
      "current layer: 43 block2b_project_bn\n",
      "current layer: 44 block2b_drop\n",
      "Found dropout, replacing ... 0.025 block2b_drop\n",
      "current layer: 45 block2b_add\n",
      "current layer: 46 block3a_expand_conv\n",
      "current layer: 47 block3a_expand_bn\n",
      "current layer: 48 block3a_expand_activation\n",
      "current layer: 49 block3a_dwconv_pad\n",
      "current layer: 50 block3a_dwconv\n",
      "current layer: 51 block3a_bn\n",
      "current layer: 52 block3a_activation\n",
      "current layer: 53 block3a_se_squeeze\n",
      "current layer: 54 block3a_se_reshape\n",
      "current layer: 55 block3a_se_reduce\n",
      "current layer: 56 block3a_se_expand\n",
      "current layer: 57 block3a_se_excite\n",
      "current layer: 58 block3a_project_conv\n",
      "current layer: 59 block3a_project_bn\n",
      "current layer: 60 block3b_expand_conv\n",
      "current layer: 61 block3b_expand_bn\n",
      "current layer: 62 block3b_expand_activation\n",
      "current layer: 63 block3b_dwconv\n",
      "current layer: 64 block3b_bn\n",
      "current layer: 65 block3b_activation\n",
      "current layer: 66 block3b_se_squeeze\n",
      "current layer: 67 block3b_se_reshape\n",
      "current layer: 68 block3b_se_reduce\n",
      "current layer: 69 block3b_se_expand\n",
      "current layer: 70 block3b_se_excite\n",
      "current layer: 71 block3b_project_conv\n",
      "current layer: 72 block3b_project_bn\n",
      "current layer: 73 block3b_drop\n",
      "Found dropout, replacing ... 0.05 block3b_drop\n",
      "current layer: 74 block3b_add\n",
      "current layer: 75 block4a_expand_conv\n",
      "current layer: 76 block4a_expand_bn\n",
      "current layer: 77 block4a_expand_activation\n",
      "current layer: 78 block4a_dwconv_pad\n",
      "current layer: 79 block4a_dwconv\n",
      "current layer: 80 block4a_bn\n",
      "current layer: 81 block4a_activation\n",
      "current layer: 82 block4a_se_squeeze\n",
      "current layer: 83 block4a_se_reshape\n",
      "current layer: 84 block4a_se_reduce\n",
      "current layer: 85 block4a_se_expand\n",
      "current layer: 86 block4a_se_excite\n",
      "current layer: 87 block4a_project_conv\n",
      "current layer: 88 block4a_project_bn\n",
      "current layer: 89 block4b_expand_conv\n",
      "current layer: 90 block4b_expand_bn\n",
      "current layer: 91 block4b_expand_activation\n",
      "current layer: 92 block4b_dwconv\n",
      "current layer: 93 block4b_bn\n",
      "current layer: 94 block4b_activation\n",
      "current layer: 95 block4b_se_squeeze\n",
      "current layer: 96 block4b_se_reshape\n",
      "current layer: 97 block4b_se_reduce\n",
      "current layer: 98 block4b_se_expand\n",
      "current layer: 99 block4b_se_excite\n",
      "current layer: 100 block4b_project_conv\n",
      "current layer: 101 block4b_project_bn\n",
      "current layer: 102 block4b_drop\n",
      "Found dropout, replacing ... 0.07500000000000001 block4b_drop\n",
      "current layer: 103 block4b_add\n",
      "current layer: 104 block4c_expand_conv\n",
      "current layer: 105 block4c_expand_bn\n",
      "current layer: 106 block4c_expand_activation\n",
      "current layer: 107 block4c_dwconv\n",
      "current layer: 108 block4c_bn\n",
      "current layer: 109 block4c_activation\n",
      "current layer: 110 block4c_se_squeeze\n",
      "current layer: 111 block4c_se_reshape\n",
      "current layer: 112 block4c_se_reduce\n",
      "current layer: 113 block4c_se_expand\n",
      "current layer: 114 block4c_se_excite\n",
      "current layer: 115 block4c_project_conv\n",
      "current layer: 116 block4c_project_bn\n",
      "current layer: 117 block4c_drop\n",
      "Found dropout, replacing ... 0.08750000000000001 block4c_drop\n",
      "current layer: 118 block4c_add\n",
      "current layer: 119 block5a_expand_conv\n",
      "current layer: 120 block5a_expand_bn\n",
      "current layer: 121 block5a_expand_activation\n",
      "current layer: 122 block5a_dwconv\n",
      "current layer: 123 block5a_bn\n",
      "current layer: 124 block5a_activation\n",
      "current layer: 125 block5a_se_squeeze\n",
      "current layer: 126 block5a_se_reshape\n",
      "current layer: 127 block5a_se_reduce\n",
      "current layer: 128 block5a_se_expand\n",
      "current layer: 129 block5a_se_excite\n",
      "current layer: 130 block5a_project_conv\n",
      "current layer: 131 block5a_project_bn\n",
      "current layer: 132 block5b_expand_conv\n",
      "current layer: 133 block5b_expand_bn\n",
      "current layer: 134 block5b_expand_activation\n",
      "current layer: 135 block5b_dwconv\n",
      "current layer: 136 block5b_bn\n",
      "current layer: 137 block5b_activation\n",
      "current layer: 138 block5b_se_squeeze\n",
      "current layer: 139 block5b_se_reshape\n",
      "current layer: 140 block5b_se_reduce\n",
      "current layer: 141 block5b_se_expand\n",
      "current layer: 142 block5b_se_excite\n",
      "current layer: 143 block5b_project_conv\n",
      "current layer: 144 block5b_project_bn\n",
      "current layer: 145 block5b_drop\n",
      "Found dropout, replacing ... 0.1125 block5b_drop\n",
      "current layer: 146 block5b_add\n",
      "current layer: 147 block5c_expand_conv\n",
      "current layer: 148 block5c_expand_bn\n",
      "current layer: 149 block5c_expand_activation\n",
      "current layer: 150 block5c_dwconv\n",
      "current layer: 151 block5c_bn\n",
      "current layer: 152 block5c_activation\n",
      "current layer: 153 block5c_se_squeeze\n",
      "current layer: 154 block5c_se_reshape\n",
      "current layer: 155 block5c_se_reduce\n",
      "current layer: 156 block5c_se_expand\n",
      "current layer: 157 block5c_se_excite\n",
      "current layer: 158 block5c_project_conv\n",
      "current layer: 159 block5c_project_bn\n",
      "current layer: 160 block5c_drop\n",
      "Found dropout, replacing ... 0.125 block5c_drop\n",
      "current layer: 161 block5c_add\n",
      "current layer: 162 block6a_expand_conv\n",
      "current layer: 163 block6a_expand_bn\n",
      "current layer: 164 block6a_expand_activation\n",
      "current layer: 165 block6a_dwconv_pad\n",
      "current layer: 166 block6a_dwconv\n",
      "current layer: 167 block6a_bn\n",
      "current layer: 168 block6a_activation\n",
      "current layer: 169 block6a_se_squeeze\n",
      "current layer: 170 block6a_se_reshape\n",
      "current layer: 171 block6a_se_reduce\n",
      "current layer: 172 block6a_se_expand\n",
      "current layer: 173 block6a_se_excite\n",
      "current layer: 174 block6a_project_conv\n",
      "current layer: 175 block6a_project_bn\n",
      "current layer: 176 block6b_expand_conv\n",
      "current layer: 177 block6b_expand_bn\n",
      "current layer: 178 block6b_expand_activation\n",
      "current layer: 179 block6b_dwconv\n",
      "current layer: 180 block6b_bn\n",
      "current layer: 181 block6b_activation\n",
      "current layer: 182 block6b_se_squeeze\n",
      "current layer: 183 block6b_se_reshape\n",
      "current layer: 184 block6b_se_reduce\n",
      "current layer: 185 block6b_se_expand\n",
      "current layer: 186 block6b_se_excite\n",
      "current layer: 187 block6b_project_conv\n",
      "current layer: 188 block6b_project_bn\n",
      "current layer: 189 block6b_drop\n",
      "Found dropout, replacing ... 0.15000000000000002 block6b_drop\n",
      "current layer: 190 block6b_add\n",
      "current layer: 191 block6c_expand_conv\n",
      "current layer: 192 block6c_expand_bn\n",
      "current layer: 193 block6c_expand_activation\n",
      "current layer: 194 block6c_dwconv\n",
      "current layer: 195 block6c_bn\n",
      "current layer: 196 block6c_activation\n",
      "current layer: 197 block6c_se_squeeze\n",
      "current layer: 198 block6c_se_reshape\n",
      "current layer: 199 block6c_se_reduce\n",
      "current layer: 200 block6c_se_expand\n",
      "current layer: 201 block6c_se_excite\n",
      "current layer: 202 block6c_project_conv\n",
      "current layer: 203 block6c_project_bn\n",
      "current layer: 204 block6c_drop\n",
      "Found dropout, replacing ... 0.1625 block6c_drop\n",
      "current layer: 205 block6c_add\n",
      "current layer: 206 block6d_expand_conv\n",
      "current layer: 207 block6d_expand_bn\n",
      "current layer: 208 block6d_expand_activation\n",
      "current layer: 209 block6d_dwconv\n",
      "current layer: 210 block6d_bn\n",
      "current layer: 211 block6d_activation\n",
      "current layer: 212 block6d_se_squeeze\n",
      "current layer: 213 block6d_se_reshape\n",
      "current layer: 214 block6d_se_reduce\n",
      "current layer: 215 block6d_se_expand\n",
      "current layer: 216 block6d_se_excite\n",
      "current layer: 217 block6d_project_conv\n",
      "current layer: 218 block6d_project_bn\n",
      "current layer: 219 block6d_drop\n",
      "Found dropout, replacing ... 0.17500000000000002 block6d_drop\n",
      "current layer: 220 block6d_add\n",
      "current layer: 221 block7a_expand_conv\n",
      "current layer: 222 block7a_expand_bn\n",
      "current layer: 223 block7a_expand_activation\n",
      "current layer: 224 block7a_dwconv\n",
      "current layer: 225 block7a_bn\n",
      "current layer: 226 block7a_activation\n",
      "current layer: 227 block7a_se_squeeze\n",
      "current layer: 228 block7a_se_reshape\n",
      "current layer: 229 block7a_se_reduce\n",
      "current layer: 230 block7a_se_expand\n",
      "current layer: 231 block7a_se_excite\n",
      "current layer: 232 block7a_project_conv\n",
      "current layer: 233 block7a_project_bn\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current layer: 234 top_conv\n",
      "current layer: 235 top_bn\n",
      "current layer: 236 top_activation\n",
      "current layer: 237 avg_pool\n",
      "current layer: 238 top_dropout\n",
      "Found dropout, replacing ... 0.2 top_dropout\n",
      "current layer: 239 predictions\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from utils import *\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "raw_model = tf.keras.applications.EfficientNetB0(\n",
    "include_top=True, weights='imagenet', input_tensor=None,\n",
    "input_shape=None, pooling=None, classes=1000,\n",
    "classifier_activation='softmax')\n",
    "export_dropout_effnet()\n",
    "dropout_model = tf.keras.models.load_model(\"models/dropout_effnetb0.h5\")\n",
    "layer_name = [i.name for i in raw_model.layers if \"activation\" in i.name][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9940ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: (224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess a sample image\n",
    "input_image = np.load(\"images/ILSVRC2012_val_00043797.npy\")\n",
    "print(\"input shape:\", input_image.shape)\n",
    "preprocessed_input = np.expand_dims(tf.keras.applications.efficientnet.preprocess_input(input_image), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "335e8a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 49\n"
     ]
    }
   ],
   "source": [
    "# Prediction of the raw model\n",
    "category_index = np.argmax(raw_model(preprocessed_input))\n",
    "print(\"Prediction:\", category_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b87f75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw grad-cam and score-cam\n",
    "gradcam_image, _ = GradCam(raw_model,\n",
    "        image = preprocessed_input,\n",
    "        category_index = category_index,\n",
    "       layer_name = layer_name,\n",
    "        raw_array = input_image,\n",
    "        dimension = 224\n",
    "       )\n",
    "scorecam_image, _ = ScoreCam(raw_model,\n",
    "        image = preprocessed_input,\n",
    "        category_index = category_index,\n",
    "       layer_name = layer_name,\n",
    "        raw_array = input_image,\n",
    "        dimension = 224\n",
    "       )\n",
    "# MC-dropout grad-cam and score-cam\n",
    "dropout_gradcam_image, _ = GradCam_Dropout(dropout_model,\n",
    "        image = preprocessed_input,\n",
    "        category_index = category_index,\n",
    "       layer_name = layer_name,\n",
    "        raw_array = input_image,\n",
    "        dimension = 224,\n",
    "        sample = 100\n",
    "       )\n",
    "dropout_scorecam_image, _ = ScoreCam_Dropout(dropout_model,\n",
    "        image = preprocessed_input,\n",
    "        category_index = category_index,\n",
    "       layer_name = layer_name,\n",
    "        raw_array = input_image,\n",
    "        dimension = 224,\n",
    "        sample = 100\n",
    "       )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
